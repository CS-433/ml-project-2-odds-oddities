{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Transformations\n",
    "\n",
    "The aim of this notebook is to test different setups with transformations using cross-validation and measure top f1 score over all epochs and folds."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44e77324caeb7103"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c3bd0b296096edc"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T14:34:10.790905Z",
     "start_time": "2023-11-20T14:34:10.782641Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ],
   "id": "a1e6b3599949a3a2"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T14:34:16.721869Z",
     "start_time": "2023-11-20T14:34:10.792380Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from scripts.preprocessing import RoadDataset, split_data\n",
    "from scripts.training import train_model\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler"
   ],
   "id": "661a28fbc323f84c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc8cd208897a9308"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T14:34:16.731066Z",
     "start_time": "2023-11-20T14:34:16.724165Z"
    }
   },
   "outputs": [],
   "source": [
    "# specify root path and train directory\n",
    "ROOT_PATH = os.path.normpath(os.getcwd() + os.sep + os.pardir)\n",
    "train_directory = os.path.join(ROOT_PATH, 'data', 'raw', 'train')"
   ],
   "id": "1c4f4dda06504ef5"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# image paths so that all the images are used for train dataset (no test set for cv due to small training set)\n",
    "image_path_train, _, mask_path_train, _ = split_data(train_directory, test_size=0)\n",
    "\n",
    "# create train Dataset without transformations for now\n",
    "train_dataset = RoadDataset(image_path_train, mask_path_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T14:34:18.139726Z",
     "start_time": "2023-11-20T14:34:16.731594Z"
    }
   },
   "id": "e5dfbbf47dcd0846"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformations\n",
    "\n",
    "Define transformations we'll use in evaluating the performance of the model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51e794b627f2d1ed"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "base_tf = [A.Resize(height=512, width=512, always_apply=True)]\n",
    "\n",
    "tf_flip = [A.HorizontalFlip(p=0.5), A.VerticalFlip(p=0.5)]\n",
    "tf_rotate = A.Rotate(p=0.5, limit=180, border_mode=cv2.BORDER_CONSTANT, rotate_method=\"ellipse\")\n",
    "tf_brightness = A.RandomBrightnessContrast(p=0.5)\n",
    "tf_snow = A.RandomSnow(p=0.1)\n",
    "\n",
    "added_tfs = np.array([tf_flip, tf_rotate, tf_brightness, tf_snow], dtype=object)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T14:34:18.141147Z",
     "start_time": "2023-11-20T14:34:18.136084Z"
    }
   },
   "id": "b8db531ec43bc422"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# initiate the setups for transformations\n",
    "col_names = ['base', 'flip', 'rotate', 'brightness', 'snow']\n",
    "masks = [\n",
    "    [False, False, False, False],\n",
    "    [True, False, False, False],\n",
    "    [True, True, False, False],\n",
    "    [True, True, True, False],\n",
    "    [True, True, True, True],\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T15:03:06.732156Z",
     "start_time": "2023-11-20T15:03:06.718043Z"
    }
   },
   "id": "87806847173ab4ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters\n",
    "\n",
    "Since our aim is to see, how different transformations influence the training, we fix the model, epochs and batch sizes."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86ca6d59a354e03a"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "ENCODER = 'resnet50'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "\n",
    "SEED = 13\n",
    "BATCH_SIZE = 4\n",
    "K_FOLD = 5\n",
    "N_CPU = os.cpu_count()\n",
    "N_EPOCHS = 100\n",
    "\n",
    "LOADER_PARAMS = {\n",
    "    'batch_size': BATCH_SIZE, \n",
    "    'num_workers': N_CPU, \n",
    "    'persistent_workers': True\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T14:43:26.476711Z",
     "start_time": "2023-11-20T14:43:26.471907Z"
    }
   },
   "id": "a6bb08833d345ec0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross-Validation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64a4294fcf3a7200"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metric_dict = {}\n",
    "\n",
    "for setup in masks:\n",
    "    \n",
    "    # get the picked tfs as list\n",
    "    tfs = added_tfs[np.array(setup)]\n",
    "    added_tfs = pd.Series(tfs).explode().tolist()\n",
    "    \n",
    "    k_fold = KFold(n_splits=K_FOLD, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    # Record K-fold results in a (K_FOLD, num_epoch) matrix\n",
    "    training_f1_matrix = []\n",
    "    validation_f1_matrix = []\n",
    "    \n",
    "    train_tf = A.Compose(base_tf + added_tfs)\n",
    "    valid_tf = A.Compose(base_tf)\n",
    "    \n",
    "    # Get training and validation indices \n",
    "    for fold, (train_idx, val_idx) in enumerate(k_fold.split(train_dataset)):\n",
    "        \n",
    "        # Create training and validation loaders by providing current K-Fold train/validation indices to Sampler\n",
    "        train_loader = DataLoader(train_dataset.set_tf(train_tf), sampler=SubsetRandomSampler(train_idx), **LOADER_PARAMS)\n",
    "        valid_loader = DataLoader(train_dataset.set_tf(valid_tf), sampler=SubsetRandomSampler(val_idx), **LOADER_PARAMS)\n",
    "        \n",
    "        # Initialize model\n",
    "        model_ = smp.create_model(\"FPN\", encoder_name=ENCODER, encoder_weights=ENCODER_WEIGHTS)\n",
    "        criterion_ = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
    "        optimizer_ = torch.optim.Adam(model_.parameters(), lr=0.0005)\n",
    "        scheduler_ = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer_,\n",
    "            T_max=(len(train_loader.dataset) * N_EPOCHS) // train_loader.batch_size,\n",
    "        )  \n",
    "    \n",
    "        # Train model\n",
    "        train_losses, valid_losses, train_f1s, valid_f1s = train_model(\n",
    "            model_, (train_loader, valid_loader), criterion_, optimizer_, scheduler_, N_EPOCHS\n",
    "        )\n",
    "        \n",
    "        # Save epoch results\n",
    "        training_f1_matrix.append(train_f1s)\n",
    "        validation_f1_matrix.append(valid_f1s)\n",
    "        \n",
    "    metric_dict[str(setup)] = validation_f1_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Metrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd70cdcdc704f9da"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "f1s = []\n",
    "std_devs = []\n",
    "\n",
    "for matrix in metric_dict.values():\n",
    "    mean_per_epoch = matrix.mean(axis=0)\n",
    "    \n",
    "    best_epoch = mean_per_epoch.argmax()\n",
    "    best_f1 = mean_per_epoch.max()\n",
    "    \n",
    "    f1s.append(mean_per_epoch.max())\n",
    "    std_devs.append(matrix[:, best_epoch].std())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T15:01:00.212194Z",
     "start_time": "2023-11-20T15:01:00.195692Z"
    }
   },
   "id": "cdfec4d7529b8b3c"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T15:03:50.825694Z",
     "start_time": "2023-11-20T15:03:50.812024Z"
    }
   },
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(index=metric_dict.keys(), columns=['top-f1', 'std'], data=np.array([f1s, std_devs]).T)"
   ],
   "id": "e8eae8e5b749d4c6"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T15:03:58.334395Z",
     "start_time": "2023-11-20T15:03:58.326395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                top-f1       std\n[False, False, False, False]  0.801848  0.216771\n[True, False, False, False]   0.809387  0.054450\n[True, True, False, False]    0.828954  0.127005\n[True, True, True, False]     0.839682  0.218645\n[True, True, True, True]      0.938499  0.038345",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>top-f1</th>\n      <th>std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>[False, False, False, False]</th>\n      <td>0.801848</td>\n      <td>0.216771</td>\n    </tr>\n    <tr>\n      <th>[True, False, False, False]</th>\n      <td>0.809387</td>\n      <td>0.054450</td>\n    </tr>\n    <tr>\n      <th>[True, True, False, False]</th>\n      <td>0.828954</td>\n      <td>0.127005</td>\n    </tr>\n    <tr>\n      <th>[True, True, True, False]</th>\n      <td>0.839682</td>\n      <td>0.218645</td>\n    </tr>\n    <tr>\n      <th>[True, True, True, True]</th>\n      <td>0.938499</td>\n      <td>0.038345</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ],
   "id": "1bdebb6ca8c9f9c0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6e0161c05bdfa70b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
