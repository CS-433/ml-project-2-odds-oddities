{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44e77324caeb7103",
   "metadata": {
    "collapsed": false,
    "id": "44e77324caeb7103"
   },
   "source": [
    "# Ensembling\n",
    "\n",
    "TODO: elaborate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3bd0b296096edc",
   "metadata": {
    "collapsed": false,
    "id": "5c3bd0b296096edc"
   },
   "source": [
    "## Google Colab\n",
    "\n",
    "The first cell will only be run in Google Colab, the second one locally as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    # noinspection PyUnresolvedReferences\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T17:59:03.747899382Z",
     "start_time": "2023-12-09T17:59:03.409787665Z"
    }
   },
   "id": "6b9c7561c0988e12"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# let's keep this cell at the beginning for every notebook\n",
    "# for more convenient training in Google Colab\n",
    "def get_root_path(filename: str) -> str: \n",
    "    \"\"\"Get root path based on notebook's name.\"\"\"\n",
    "    filepath = glob.glob(os.getcwd() + '/**/' + filename, recursive = True)[0]\n",
    "    return os.path.dirname(os.path.dirname(filepath))\n",
    "\n",
    "ROOT_PATH = get_root_path('ensembling.ipynb')\n",
    "sys.path.append(ROOT_PATH)\n",
    "\n",
    "# go to the drive directory\n",
    "os.chdir(ROOT_PATH) if IN_COLAB else None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T17:59:03.748182278Z",
     "start_time": "2023-12-09T17:59:03.726334570Z"
    }
   },
   "id": "6ca28bc5245f155c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d624e0026c589fad"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_54642/207476987.py:13: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  from distutils.spawn import find_executable\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import itertools\n",
    "\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from matplotlib import colors\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from distutils.spawn import find_executable\n",
    "from scripts.evaluation import EvaluationMonitor, get_best_f1_per_setup, PredictionMonitor\n",
    "from scripts.preprocessing import RoadDataset, split_data\n",
    "from scripts.training import train_model, setup_seed, valid_epoch, train_epoch\n",
    "from scripts.plotting import plot_post_processing, plot_images\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T17:59:05.843312922Z",
     "start_time": "2023-12-09T17:59:03.731104832Z"
    }
   },
   "id": "661a28fbc323f84c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# necessary for downloading some of the models\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T17:59:05.847978016Z",
     "start_time": "2023-12-09T17:59:05.844945312Z"
    }
   },
   "id": "fa5d6575c4861306"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "setup_seed(16)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T17:59:05.854352878Z",
     "start_time": "2023-12-09T17:59:05.846763313Z"
    }
   },
   "id": "4db7d71f1c441221"
  },
  {
   "cell_type": "markdown",
   "id": "cc8cd208897a9308",
   "metadata": {
    "collapsed": false,
    "id": "cc8cd208897a9308"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c4f4dda06504ef5",
   "metadata": {
    "executionInfo": {
     "elapsed": 443,
     "status": "ok",
     "timestamp": 1700508609231,
     "user": {
      "displayName": "Jan Kokla",
      "userId": "12594254134589162600"
     },
     "user_tz": -60
    },
    "id": "1c4f4dda06504ef5",
    "ExecuteTime": {
     "end_time": "2023-12-09T17:59:05.858026563Z",
     "start_time": "2023-12-09T17:59:05.854475478Z"
    }
   },
   "outputs": [],
   "source": [
    "# specify train directory\n",
    "train_directory = os.path.join(ROOT_PATH, 'data', 'raw', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5dfbbf47dcd0846",
   "metadata": {
    "executionInfo": {
     "elapsed": 66794,
     "status": "ok",
     "timestamp": 1700508678052,
     "user": {
      "displayName": "Jan Kokla",
      "userId": "12594254134589162600"
     },
     "user_tz": -60
    },
    "id": "e5dfbbf47dcd0846",
    "ExecuteTime": {
     "end_time": "2023-12-09T17:59:06.340225896Z",
     "start_time": "2023-12-09T17:59:05.856763417Z"
    }
   },
   "outputs": [],
   "source": [
    "# image paths so that all the images are used for train dataset (no test set for cv due to small training set)\n",
    "image_path_train, _, mask_path_train, _ = split_data(train_directory, test_size=0)\n",
    "\n",
    "# create train Dataset without transformations for now\n",
    "train_dataset = RoadDataset(image_path_train, mask_path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8db531ec43bc422",
   "metadata": {
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1700508685005,
     "user": {
      "displayName": "Jan Kokla",
      "userId": "12594254134589162600"
     },
     "user_tz": -60
    },
    "id": "b8db531ec43bc422",
    "ExecuteTime": {
     "end_time": "2023-12-09T17:59:06.344140711Z",
     "start_time": "2023-12-09T17:59:06.343126453Z"
    }
   },
   "outputs": [],
   "source": [
    "# define transformations\n",
    "train_tf = A.Compose([\n",
    "    A.Resize(height=608, width=608, always_apply=True),\n",
    "    A.Rotate(p=0.5, limit=180, border_mode=cv2.BORDER_CONSTANT, rotate_method=\"ellipse\"),\n",
    "    A.RandomBrightnessContrast(p=0.5)\n",
    "])\n",
    "\n",
    "valid_tf = A.Compose([A.Resize(height=608, width=608, always_apply=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ca6d59a354e03a",
   "metadata": {
    "collapsed": false,
    "id": "86ca6d59a354e03a"
   },
   "source": [
    "## Hyperparameters\n",
    "\n",
    "Since our aim is to see, how different architectures influence the training, we fix the model, epochs and batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6bb08833d345ec0",
   "metadata": {
    "executionInfo": {
     "elapsed": 761,
     "status": "ok",
     "timestamp": 1700508695367,
     "user": {
      "displayName": "Jan Kokla",
      "userId": "12594254134589162600"
     },
     "user_tz": -60
    },
    "id": "a6bb08833d345ec0",
    "ExecuteTime": {
     "end_time": "2023-12-09T17:59:06.857309320Z",
     "start_time": "2023-12-09T17:59:06.345014641Z"
    }
   },
   "outputs": [],
   "source": [
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "\n",
    "SEED = 16\n",
    "BATCH_SIZE = 4\n",
    "K_FOLD = 3\n",
    "N_CPU = os.cpu_count()\n",
    "N_EPOCHS = 2\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "LOADER_PARAMS = {\n",
    "    'batch_size': BATCH_SIZE\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encode-Decoder Combinations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51e794b627f2d1ed"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# specify the root path for evaluation json-s\n",
    "encoder_decoder = [\n",
    "    #('resnet34', 'Unet'),\n",
    "    #('resnet18', 'Unet'),\n",
    "    ('resnet18', 'Unet'),\n",
    "    #('resnet101', 'DeepLabV3'), \n",
    "    #('vgg19', 'UnetPlusPlus'), \n",
    "    #('inceptionv4', 'UnetPlusPlus'), \n",
    "    #('mit_b2', 'Unet'), \n",
    "    #('efficientnet-b4', 'UnetPlusPlus')\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T17:59:06.897879043Z",
     "start_time": "2023-12-09T17:59:06.858394844Z"
    }
   },
   "id": "87806847173ab4ed"
  },
  {
   "cell_type": "markdown",
   "id": "64a4294fcf3a7200",
   "metadata": {
    "collapsed": false,
    "id": "64a4294fcf3a7200"
   },
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "eval_monitor = EvaluationMonitor(os.path.join(ROOT_PATH, 'data', 'results', 'ensembling'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T17:59:06.905289645Z",
     "start_time": "2023-12-09T17:59:06.898477514Z"
    }
   },
   "id": "4147156d1bd303a8"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   1. Train.      Loss: 0.620 | f1: 0.456: 100%|██████████| 17/17 [00:04<00:00,  3.52it/s]\n",
      "Epoch:   1. Validation. Loss: 0.497 | f1: 0.596: 100%|██████████| 9/9 [00:00<00:00, 12.29it/s]\n",
      "Epoch:   2. Train.      Loss: 0.469 | f1: 0.650: 100%|██████████| 17/17 [00:03<00:00,  5.05it/s]\n",
      "Epoch:   2. Validation. Loss: 0.451 | f1: 0.619: 100%|██████████| 9/9 [00:00<00:00, 12.17it/s]\n",
      "Epoch:   1. Train.      Loss: 0.616 | f1: 0.454: 100%|██████████| 17/17 [00:03<00:00,  4.98it/s]\n",
      "Epoch:   1. Validation. Loss: 0.594 | f1: 0.463: 100%|██████████| 9/9 [00:00<00:00, 12.88it/s]\n",
      "Epoch:   2. Train.      Loss: 0.512 | f1: 0.616: 100%|██████████| 17/17 [00:03<00:00,  5.02it/s]\n",
      "Epoch:   2. Validation. Loss: 0.471 | f1: 0.680: 100%|██████████| 9/9 [00:00<00:00, 13.37it/s]\n",
      "Epoch:   1. Train.      Loss: 0.611 | f1: 0.480: 100%|██████████| 17/17 [00:03<00:00,  4.95it/s]\n",
      "Epoch:   1. Validation. Loss: 0.415 | f1: 0.633: 100%|██████████| 9/9 [00:00<00:00, 13.02it/s]\n",
      "Epoch:   2. Train.      Loss: 0.456 | f1: 0.650: 100%|██████████| 17/17 [00:03<00:00,  5.38it/s]\n",
      "Epoch:   2. Validation. Loss: 0.449 | f1: 0.646: 100%|██████████| 9/9 [00:00<00:00,  9.73it/s]\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "\n",
    "k_fold = KFold(n_splits=K_FOLD, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Get training and validation indices\n",
    "for fold, (train_idx, val_idx) in enumerate(k_fold.split(train_dataset)):\n",
    "    \n",
    "    # Create training and validation loaders by providing current K-Fold train/validation indices to Sampler\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset.set_tf(train_tf), sampler=SubsetRandomSampler(train_idx), **LOADER_PARAMS\n",
    "    )\n",
    "    \n",
    "    valid_loader = DataLoader(\n",
    "        train_dataset.set_tf(valid_tf), sampler=SubsetRandomSampler(val_idx), **LOADER_PARAMS\n",
    "    )\n",
    "    \n",
    "    models = [\n",
    "        smp.create_model(\n",
    "            decoder, encoder_name=encoder, encoder_weights=ENCODER_WEIGHTS\n",
    "        ).to(DEVICE) for encoder, decoder in encoder_decoder\n",
    "    ]\n",
    "    \n",
    "    optimizers = [torch.optim.Adam(model_.parameters(), lr=0.0005) for model_ in models]\n",
    "    # TODO add comment\n",
    "    t_max = (len(train_loader.dataset) * N_EPOCHS) // train_loader.batch_size\n",
    "    schedulers = [CosineAnnealingLR(optimizer_, T_max=t_max,) for optimizer_ in optimizers]\n",
    "    criterion_ = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
    "    \n",
    "    zipped_values = [encoder_decoder, models, optimizers, schedulers]\n",
    "    \n",
    "    for i in range(N_EPOCHS):\n",
    "        \n",
    "        pred_monitor = PredictionMonitor()\n",
    "        \n",
    "        # since we want to have the same transformations for every model\n",
    "        train_data = [(image, mask) for image, mask in train_loader]\n",
    "        valid_data = [(image, mask) for image, mask in valid_loader]\n",
    "        \n",
    "        for (enc, dec), model_, opt_, sched_ in zip(*zipped_values):\n",
    "            \n",
    "            pred_monitor.set_model(enc, dec)\n",
    "    \n",
    "            _, train_f1 = train_epoch(\n",
    "                model_, train_data, criterion_, opt_, sched_, i + 1, monitor=pred_monitor\n",
    "            )\n",
    "            _, valid_f1 = valid_epoch(\n",
    "                model_, valid_data, criterion_, i + 1, monitor=pred_monitor\n",
    "            )\n",
    "            \n",
    "            eval_monitor.update_metrics_by_fold(\n",
    "                setup='+'.join([enc, dec]), \n",
    "                fold=fold, \n",
    "                training_f1=train_f1,\n",
    "                validation_f1=valid_f1\n",
    "            )\n",
    "        \n",
    "        # meta learner\n",
    "            \n",
    "        x_train, y_train = pred_monitor.get_ensembling_for_models(encoder_decoder, mode='training')\n",
    "        #clf = RandomForestClassifier(max_depth=2, n_jobs=5, random_state=SEED)\n",
    "        \n",
    "        #y_train_pred = x_train.mode(axis=1).to_numpy().squeeze()\n",
    "        y_train_pred = (x_train.sum(axis=1) >= 1).astype(int).to_numpy()\n",
    "        #clf.fit(x_train, y_train)\n",
    "        train_f1 = f1_score(y_train, y_train_pred)\n",
    "        \n",
    "        x_val, y_val = pred_monitor.get_ensembling_for_models(encoder_decoder, mode='validation')\n",
    "        #y_val_pred = x_val.mode(axis=1).to_numpy().squeeze()\n",
    "        y_val_pred = (x_val.sum(axis=1) >= 1).astype(int).to_numpy()\n",
    "        valid_f1 = f1_score(y_val, y_val_pred)\n",
    "        \n",
    "        eval_monitor.update_metrics_by_fold(\n",
    "            setup='ensembling', \n",
    "            fold=fold, \n",
    "            training_f1=train_f1,\n",
    "            validation_f1=valid_f1\n",
    "        )\n",
    "    \n",
    "    eval_monitor.update_jsons()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T18:00:41.480532850Z",
     "start_time": "2023-12-09T17:59:06.906868062Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ensembling\n",
    "\n",
    "CV was run on colab, the predictions saved to JSON, and now we can apply ensembling."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd70cdcdc704f9da"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T18:00:41.526598241Z",
     "start_time": "2023-12-09T18:00:41.526033568Z"
    }
   },
   "id": "27837020bd5423fd"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
