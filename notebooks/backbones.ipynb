{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44e77324caeb7103",
   "metadata": {
    "collapsed": false,
    "id": "44e77324caeb7103"
   },
   "source": [
    "# Architectures\n",
    "\n",
    "The aim of this notebook is to test different encoder-decoder combinations.Based on the earlier results, we limited the decoders to two most successful ones:\n",
    "\n",
    "- [Unet++](https://arxiv.org/pdf/1807.10165.pdf)\n",
    "- [DeepLabV3](https://arxiv.org/abs/1706.05587)\n",
    "\n",
    "These will now be combined with different encoders:\n",
    "- [ResNet](https://arxiv.org/abs/1512.03385)\n",
    "- [ResNeXt](https://arxiv.org/abs/1611.05431)\n",
    "- [VGG](https://arxiv.org/abs/1409.1556)\n",
    "- [EfficientNet](https://arxiv.org/abs/1905.11946)\n",
    "- [Inception](https://arxiv.org/abs/1409.4842)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3bd0b296096edc",
   "metadata": {
    "collapsed": false,
    "id": "5c3bd0b296096edc"
   },
   "source": [
    "## Google Colab\n",
    "\n",
    "The first cell will only be run in Google Colab, the second one locally as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    # noinspection PyUnresolvedReferences\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T11:38:30.593835Z",
     "start_time": "2023-11-30T11:38:30.546903Z"
    }
   },
   "id": "6b9c7561c0988e12"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# let's keep this cell at the beginning for every notebook\n",
    "# for more convenient training in Google Colab\n",
    "def get_root_path(filename: str) -> str: \n",
    "    \"\"\"Get root path based on notebook's name.\"\"\"\n",
    "    filepath = glob.glob(os.getcwd() + '/**/' + filename, recursive = True)[0]\n",
    "    return os.path.dirname(os.path.dirname(filepath))\n",
    "\n",
    "ROOT_PATH = get_root_path('backbones.ipynb')\n",
    "sys.path.append(ROOT_PATH)\n",
    "\n",
    "# go to the drive directory\n",
    "os.chdir(ROOT_PATH) if IN_COLAB else None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T11:38:30.595244Z",
     "start_time": "2023-11-30T11:38:30.561188Z"
    }
   },
   "id": "6ca28bc5245f155c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d624e0026c589fad"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "import albumentations as A\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from scripts.evaluation import EvaluationMonitor\n",
    "from scripts.preprocessing import RoadDataset, split_data\n",
    "from scripts.training import train_model\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T11:39:53.229501Z",
     "start_time": "2023-11-30T11:39:53.225309Z"
    }
   },
   "id": "661a28fbc323f84c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# necessary for downloading some of the models\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa5d6575c4861306"
  },
  {
   "cell_type": "markdown",
   "id": "cc8cd208897a9308",
   "metadata": {
    "collapsed": false,
    "id": "cc8cd208897a9308"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c4f4dda06504ef5",
   "metadata": {
    "executionInfo": {
     "elapsed": 443,
     "status": "ok",
     "timestamp": 1700508609231,
     "user": {
      "displayName": "Jan Kokla",
      "userId": "12594254134589162600"
     },
     "user_tz": -60
    },
    "id": "1c4f4dda06504ef5",
    "ExecuteTime": {
     "end_time": "2023-11-30T11:39:54.009280Z",
     "start_time": "2023-11-30T11:39:54.001558Z"
    }
   },
   "outputs": [],
   "source": [
    "# specify train directory\n",
    "train_directory = os.path.join(ROOT_PATH, 'data', 'raw', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5dfbbf47dcd0846",
   "metadata": {
    "executionInfo": {
     "elapsed": 66794,
     "status": "ok",
     "timestamp": 1700508678052,
     "user": {
      "displayName": "Jan Kokla",
      "userId": "12594254134589162600"
     },
     "user_tz": -60
    },
    "id": "e5dfbbf47dcd0846",
    "ExecuteTime": {
     "end_time": "2023-11-30T11:39:56.865937Z",
     "start_time": "2023-11-30T11:39:54.560622Z"
    }
   },
   "outputs": [],
   "source": [
    "# image paths so that all the images are used for train dataset (no test set for cv due to small training set)\n",
    "image_path_train, _, mask_path_train, _ = split_data(train_directory, test_size=0)\n",
    "\n",
    "# create train Dataset without transformations for now\n",
    "train_dataset = RoadDataset(image_path_train, mask_path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8db531ec43bc422",
   "metadata": {
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1700508685005,
     "user": {
      "displayName": "Jan Kokla",
      "userId": "12594254134589162600"
     },
     "user_tz": -60
    },
    "id": "b8db531ec43bc422",
    "ExecuteTime": {
     "end_time": "2023-11-30T11:39:56.873472Z",
     "start_time": "2023-11-30T11:39:56.870759Z"
    }
   },
   "outputs": [],
   "source": [
    "# define transformations\n",
    "train_tf = A.Compose([\n",
    "    A.Resize(height=608, width=608, always_apply=True),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Rotate(p=0.5, limit=180, border_mode=cv2.BORDER_CONSTANT, rotate_method=\"ellipse\"),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.RandomSnow(p=0.1)\n",
    "])\n",
    "\n",
    "valid_tf = A.Compose([A.Resize(height=608, width=608, always_apply=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encode-Decoder Combinations\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51e794b627f2d1ed"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6166fb69af48c699"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87806847173ab4ed",
   "metadata": {
    "executionInfo": {
     "elapsed": 301,
     "status": "ok",
     "timestamp": 1700508686557,
     "user": {
      "displayName": "Jan Kokla",
      "userId": "12594254134589162600"
     },
     "user_tz": -60
    },
    "id": "87806847173ab4ed",
    "ExecuteTime": {
     "end_time": "2023-11-30T11:48:05.554415Z",
     "start_time": "2023-11-30T11:48:05.542817Z"
    }
   },
   "outputs": [],
   "source": [
    "# specify the root path for evaluation json-s\n",
    "evaluation_dir = os.path.join(ROOT_PATH, 'data', 'results', 'backbone')\n",
    "monitor = EvaluationMonitor(evaluation_dir)\n",
    "ENC_DEC_COMBINATIONS = monitor.get_not_updated_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ENC_DEC_COMBINATIONS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8c4a0aacbe40fd1"
  },
  {
   "cell_type": "markdown",
   "id": "86ca6d59a354e03a",
   "metadata": {
    "collapsed": false,
    "id": "86ca6d59a354e03a"
   },
   "source": [
    "## Hyperparameters\n",
    "\n",
    "Since our aim is to see, how different architectures influence the training, we fix the model, epochs and batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6bb08833d345ec0",
   "metadata": {
    "executionInfo": {
     "elapsed": 761,
     "status": "ok",
     "timestamp": 1700508695367,
     "user": {
      "displayName": "Jan Kokla",
      "userId": "12594254134589162600"
     },
     "user_tz": -60
    },
    "id": "a6bb08833d345ec0",
    "ExecuteTime": {
     "end_time": "2023-11-30T11:48:08.151395Z",
     "start_time": "2023-11-30T11:48:08.144761Z"
    }
   },
   "outputs": [],
   "source": [
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "\n",
    "PARAMETER_COUNT = {\n",
    "    'resnet101': 42,\n",
    "    'resnext101_32x8d': 86,\n",
    "    'vgg19': 20,\n",
    "    'efficientnet-b7': 63,\n",
    "    'inceptionv4': 41\n",
    "}\n",
    "\n",
    "SEED = 16\n",
    "BATCH_SIZE = 4\n",
    "K_FOLD = 3\n",
    "N_CPU = os.cpu_count()\n",
    "N_EPOCHS = 150\n",
    "\n",
    "LOADER_PARAMS = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'num_workers': N_CPU,\n",
    "    'persistent_workers': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T11:48:11.953064Z",
     "start_time": "2023-11-30T11:48:11.941198Z"
    }
   },
   "id": "71835a725ecb855b"
  },
  {
   "cell_type": "markdown",
   "id": "64a4294fcf3a7200",
   "metadata": {
    "collapsed": false,
    "id": "64a4294fcf3a7200"
   },
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 705616,
     "status": "ok",
     "timestamp": 1700509405450,
     "user": {
      "displayName": "Jan Kokla",
      "userId": "12594254134589162600"
     },
     "user_tz": -60
    },
    "id": "initial_id",
    "outputId": "0051ace9-0448-4556-f4af-58d3f1cf7df9"
   },
   "outputs": [],
   "source": [
    "for encoder, decoder in ENC_DEC_COMBINATIONS:\n",
    "\n",
    "    print(f'encoder-decoder: {encoder}-{decoder}')\n",
    "\n",
    "    k_fold = KFold(n_splits=K_FOLD, shuffle=True, random_state=SEED)\n",
    "\n",
    "    # Record K-fold results in a (K_FOLD, num_epoch) matrix\n",
    "    training_loss_matrix = []\n",
    "    validation_loss_matrix = []\n",
    "    training_f1_matrix = []\n",
    "    validation_f1_matrix = []\n",
    "\n",
    "    # Get training and validation indices\n",
    "    for fold, (train_idx, val_idx) in enumerate(k_fold.split(train_dataset)):\n",
    "\n",
    "        print(f'fold: {fold}')\n",
    "\n",
    "        # Create training and validation loaders by providing current K-Fold train/validation indices to Sampler\n",
    "        train_loader = DataLoader(train_dataset.set_tf(train_tf), sampler=SubsetRandomSampler(train_idx), **LOADER_PARAMS)\n",
    "        valid_loader = DataLoader(train_dataset.set_tf(valid_tf), sampler=SubsetRandomSampler(val_idx), **LOADER_PARAMS)\n",
    "\n",
    "        # Initialize model\n",
    "        model_ = smp.create_model(decoder, encoder_name=encoder, encoder_weights=ENCODER_WEIGHTS)\n",
    "        criterion_ = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
    "        optimizer_ = torch.optim.Adam(model_.parameters(), lr=0.0005)\n",
    "        scheduler_ = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer_,\n",
    "            T_max=(len(train_loader.dataset) * N_EPOCHS) // train_loader.batch_size,\n",
    "        )\n",
    "\n",
    "        # Train model\n",
    "        train_losses, valid_losses, train_f1s, valid_f1s = train_model(\n",
    "            model_, (train_loader, valid_loader), criterion_, optimizer_, scheduler_, N_EPOCHS\n",
    "        )\n",
    "\n",
    "        # Save epoch results\n",
    "        training_loss_matrix.append(train_f1s)\n",
    "        validation_loss_matrix.append(train_f1s)\n",
    "        training_f1_matrix.append(train_f1s)\n",
    "        validation_f1_matrix.append(valid_f1s)\n",
    "    \n",
    "    monitor.update_metrics(\n",
    "        (encoder, decoder),\n",
    "        training_f1=training_f1_matrix,\n",
    "        training_loss=training_loss_matrix,\n",
    "        validation_f1=validation_f1_matrix,\n",
    "        validation_loss=validation_loss_matrix\n",
    "    )\n",
    "    monitor.update_jsons()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Metrics\n",
    "\n",
    "CV was run on colab, the results saved to JSON, and now we can start analysing them."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd70cdcdc704f9da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-28T09:33:51.443508Z"
    }
   },
   "id": "ae22b5f98a889be5"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
