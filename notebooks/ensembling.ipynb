{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44e77324caeb7103",
   "metadata": {
    "collapsed": false,
    "id": "44e77324caeb7103"
   },
   "source": [
    "# Ensembling\n",
    "\n",
    "TODO: elaborate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3bd0b296096edc",
   "metadata": {
    "collapsed": false,
    "id": "5c3bd0b296096edc"
   },
   "source": [
    "## Google Colab\n",
    "\n",
    "The first cell will only be run in Google Colab, the second one locally as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    # noinspection PyUnresolvedReferences\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T17:29:53.127071Z",
     "start_time": "2023-12-11T17:29:53.069240Z"
    }
   },
   "id": "6b9c7561c0988e12"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# let's keep this cell at the beginning for every notebook\n",
    "# for more convenient training in Google Colab\n",
    "def get_root_path(filename: str) -> str: \n",
    "    \"\"\"Get root path based on notebook's name.\"\"\"\n",
    "    filepath = glob.glob(os.getcwd() + '/**/' + filename, recursive = True)[0]\n",
    "    return os.path.dirname(os.path.dirname(filepath))\n",
    "\n",
    "ROOT_PATH = get_root_path('ensembling.ipynb')\n",
    "sys.path.append(ROOT_PATH)\n",
    "\n",
    "# go to the drive directory\n",
    "os.chdir(ROOT_PATH) if IN_COLAB else None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T17:29:53.127473Z",
     "start_time": "2023-12-11T17:29:53.084840Z"
    }
   },
   "id": "6ca28bc5245f155c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d624e0026c589fad"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "import albumentations as A\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from scripts.evaluation import EvaluationMonitor, Ensembler\n",
    "from scripts.preprocessing import RoadDataset, split_data\n",
    "from scripts.training import setup_seed, valid_epoch, train_epoch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T17:29:59.489688Z",
     "start_time": "2023-12-11T17:29:53.089988Z"
    }
   },
   "id": "661a28fbc323f84c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# necessary for downloading some of the models\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T17:29:59.497775Z",
     "start_time": "2023-12-11T17:29:59.490123Z"
    }
   },
   "id": "fa5d6575c4861306"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "setup_seed(16)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T17:29:59.507911Z",
     "start_time": "2023-12-11T17:29:59.496508Z"
    }
   },
   "id": "4db7d71f1c441221"
  },
  {
   "cell_type": "markdown",
   "id": "cc8cd208897a9308",
   "metadata": {
    "collapsed": false,
    "id": "cc8cd208897a9308"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c4f4dda06504ef5",
   "metadata": {
    "executionInfo": {
     "elapsed": 443,
     "status": "ok",
     "timestamp": 1700508609231,
     "user": {
      "displayName": "Jan Kokla",
      "userId": "12594254134589162600"
     },
     "user_tz": -60
    },
    "id": "1c4f4dda06504ef5",
    "ExecuteTime": {
     "end_time": "2023-12-11T17:29:59.509876Z",
     "start_time": "2023-12-11T17:29:59.503261Z"
    }
   },
   "outputs": [],
   "source": [
    "# specify train directory\n",
    "train_directory = os.path.join(ROOT_PATH, 'data', 'raw', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5dfbbf47dcd0846",
   "metadata": {
    "executionInfo": {
     "elapsed": 66794,
     "status": "ok",
     "timestamp": 1700508678052,
     "user": {
      "displayName": "Jan Kokla",
      "userId": "12594254134589162600"
     },
     "user_tz": -60
    },
    "id": "e5dfbbf47dcd0846",
    "ExecuteTime": {
     "end_time": "2023-12-11T17:30:00.755670Z",
     "start_time": "2023-12-11T17:29:59.510629Z"
    }
   },
   "outputs": [],
   "source": [
    "# image paths so that all the images are used for train dataset (no test set for cv due to small training set)\n",
    "image_path_train, _, mask_path_train, _ = split_data(train_directory, test_size=0)\n",
    "\n",
    "# create train Dataset without transformations for now\n",
    "train_dataset = RoadDataset(image_path_train, mask_path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8db531ec43bc422",
   "metadata": {
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1700508685005,
     "user": {
      "displayName": "Jan Kokla",
      "userId": "12594254134589162600"
     },
     "user_tz": -60
    },
    "id": "b8db531ec43bc422",
    "ExecuteTime": {
     "end_time": "2023-12-11T17:30:00.764183Z",
     "start_time": "2023-12-11T17:30:00.756334Z"
    }
   },
   "outputs": [],
   "source": [
    "# define transformations\n",
    "train_tf = A.Compose([\n",
    "    A.Resize(height=608, width=608, always_apply=True),\n",
    "    A.Rotate(p=0.5, limit=180, border_mode=cv2.BORDER_CONSTANT, rotate_method=\"ellipse\"),\n",
    "    A.RandomBrightnessContrast(p=0.5)\n",
    "])\n",
    "\n",
    "valid_tf = A.Compose([A.Resize(height=608, width=608, always_apply=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ca6d59a354e03a",
   "metadata": {
    "collapsed": false,
    "id": "86ca6d59a354e03a"
   },
   "source": [
    "## Hyperparameters\n",
    "\n",
    "Since our aim is to see, how different architectures influence the training, we fix the model, epochs and batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6bb08833d345ec0",
   "metadata": {
    "executionInfo": {
     "elapsed": 761,
     "status": "ok",
     "timestamp": 1700508695367,
     "user": {
      "displayName": "Jan Kokla",
      "userId": "12594254134589162600"
     },
     "user_tz": -60
    },
    "id": "a6bb08833d345ec0",
    "ExecuteTime": {
     "end_time": "2023-12-11T17:30:00.772768Z",
     "start_time": "2023-12-11T17:30:00.762793Z"
    }
   },
   "outputs": [],
   "source": [
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "\n",
    "SEED = 16\n",
    "BATCH_SIZE = 4\n",
    "K_FOLD = 3\n",
    "N_CPU = os.cpu_count()\n",
    "N_EPOCHS = 5\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "LOADER_PARAMS = {\n",
    "    'batch_size': BATCH_SIZE\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encode-Decoder Combinations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51e794b627f2d1ed"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# specify the root path for evaluation json-s\n",
    "encoder_decoder = [\n",
    "    ('inceptionv4', 'UnetPlusPlus'), \n",
    "    ('mit_b2', 'Unet'), \n",
    "    ('efficientnet-b4', 'UnetPlusPlus')\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T17:30:00.773136Z",
     "start_time": "2023-12-11T17:30:00.767937Z"
    }
   },
   "id": "87806847173ab4ed"
  },
  {
   "cell_type": "markdown",
   "id": "64a4294fcf3a7200",
   "metadata": {
    "collapsed": false,
    "id": "64a4294fcf3a7200"
   },
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "eval_monitor = EvaluationMonitor(os.path.join(ROOT_PATH, 'data', 'results', 'ensembling'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T17:30:00.783873Z",
     "start_time": "2023-12-11T17:30:00.772510Z"
    }
   },
   "id": "4147156d1bd303a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "k_fold = KFold(n_splits=K_FOLD, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Get training and validation indices\n",
    "for fold, (train_idx, val_idx) in enumerate(k_fold.split(train_dataset)):\n",
    "    \n",
    "    # Create training and validation loaders by providing current K-Fold train/validation indices to Sampler\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset.set_tf(train_tf), sampler=SubsetRandomSampler(train_idx), **LOADER_PARAMS\n",
    "    )\n",
    "    \n",
    "    valid_loader = DataLoader(\n",
    "        train_dataset.set_tf(valid_tf), sampler=SubsetRandomSampler(val_idx), **LOADER_PARAMS\n",
    "    )\n",
    "    \n",
    "    models = [\n",
    "        smp.create_model(\n",
    "            decoder, encoder_name=encoder, encoder_weights=ENCODER_WEIGHTS\n",
    "        ).to(DEVICE) for encoder, decoder in encoder_decoder\n",
    "    ]\n",
    "    \n",
    "    optimizers = [torch.optim.Adam(model_.parameters(), lr=0.0005) for model_ in models]\n",
    "    # TODO add comment\n",
    "    t_max = (len(train_loader.dataset) * N_EPOCHS) // train_loader.batch_size\n",
    "    schedulers = [CosineAnnealingLR(optimizer_, T_max=t_max,) for optimizer_ in optimizers]\n",
    "    criterion_ = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
    "    \n",
    "    zipped_values = [encoder_decoder, models, optimizers, schedulers]\n",
    "    \n",
    "    for i in range(N_EPOCHS):\n",
    "        \n",
    "        ensembler = Ensembler()\n",
    "        \n",
    "        # since we want to have the same transformations for every model\n",
    "        train_data = [(image, mask) for image, mask in train_loader]\n",
    "        valid_data = [(image, mask) for image, mask in valid_loader]\n",
    "        \n",
    "        for (enc, dec), model_, opt_, sched_ in zip(*zipped_values):\n",
    "            \n",
    "            ensembler.set_model(enc, dec)\n",
    "    \n",
    "            _, train_f1 = train_epoch(\n",
    "                model_, train_data, criterion_, opt_, sched_, i + 1, ensembler=ensembler\n",
    "            )\n",
    "            _, valid_f1 = valid_epoch(\n",
    "                model_, valid_data, criterion_, i + 1, ensembler=ensembler\n",
    "            )\n",
    "            \n",
    "            eval_monitor.update_metrics_by_fold(\n",
    "                setup='+'.join([enc, dec]), \n",
    "                fold=fold, \n",
    "                training_f1=train_f1,\n",
    "                validation_f1=valid_f1\n",
    "            )\n",
    "        \n",
    "        # meta learner\n",
    "        eval_monitor.update_metrics_by_fold(\n",
    "            setup='ensembling', \n",
    "            fold=fold, \n",
    "            training_f1=ensembler.get_f1('training'),\n",
    "            validation_f1=ensembler.get_f1('validation')\n",
    "        )\n",
    "    \n",
    "    eval_monitor.update_jsons()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ensembling\n",
    "\n",
    "CV was run on colab, the predictions saved to JSON, and now we can apply ensembling."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd70cdcdc704f9da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8eea3e5a5af45f76"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
