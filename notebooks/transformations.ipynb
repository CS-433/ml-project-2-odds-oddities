{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44e77324caeb7103",
   "metadata": {
    "collapsed": false,
    "id": "44e77324caeb7103"
   },
   "source": [
    "# Transformations\n",
    "\n",
    "The aim of this notebook is to test different setups with transformations using cross-validation and measure top f1 score over all epochs and folds.\n",
    "\n",
    "NB! Running this notebook takes roughly 7-8 hours on a GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3bd0b296096edc",
   "metadata": {
    "collapsed": false,
    "id": "5c3bd0b296096edc"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "661a28fbc323f84c",
   "metadata": {
    "executionInfo": {
     "elapsed": 16594,
     "status": "ok",
     "timestamp": 1700508603161,
     "user": {
      "displayName": "Jan Kokla",
      "userId": "12594254134589162600"
     },
     "user_tz": -60
    },
    "id": "661a28fbc323f84c",
    "ExecuteTime": {
     "end_time": "2023-12-09T16:25:42.457080109Z",
     "start_time": "2023-12-09T16:25:40.262068872Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import segmentation_models_pytorch as smp\n",
    "import time\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from scripts.preprocessing import RoadDataset, split_data\n",
    "from scripts.training import train_model\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Add a time delay before starting the cross validation\n",
    "\n",
    "# hours = 1\n",
    "# minutes = 0\n",
    "# \n",
    "# for sec in range(minutes*60 + hours*3600, 0, -1):\n",
    "#     print(f\"Starting in {int(sec/3600)}:{int(sec%3600 / 60):}:{sec % 60}\", end=\"\\r\")\n",
    "#     time.sleep(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:25:42.459437190Z",
     "start_time": "2023-12-09T16:25:42.457190044Z"
    }
   },
   "id": "c139718a338a6c89"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    # noinspection PyUnresolvedReferences\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "# let's keep this cell at the beginning for every notebook\n",
    "# for more convenient training in Google Colab\n",
    "def get_root_path(filename: str) -> str: \n",
    "    \"\"\"Get root path based on notebook's name.\"\"\"\n",
    "    filepath = glob.glob(os.getcwd() + '/**/' + filename, recursive = True)[0]\n",
    "    return os.path.dirname(os.path.dirname(filepath))\n",
    "\n",
    "ROOT_PATH = get_root_path('transformations.ipynb')\n",
    "sys.path.append(ROOT_PATH)\n",
    "\n",
    "# go to the drive directory\n",
    "os.chdir(ROOT_PATH) if IN_COLAB else None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:25:42.467361874Z",
     "start_time": "2023-12-09T16:25:42.460137952Z"
    }
   },
   "id": "28ecdaa1b7cf8d36"
  },
  {
   "cell_type": "markdown",
   "id": "cc8cd208897a9308",
   "metadata": {
    "collapsed": false,
    "id": "cc8cd208897a9308"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c4f4dda06504ef5",
   "metadata": {
    "executionInfo": {
     "elapsed": 443,
     "status": "ok",
     "timestamp": 1700508609231,
     "user": {
      "displayName": "Jan Kokla",
      "userId": "12594254134589162600"
     },
     "user_tz": -60
    },
    "id": "1c4f4dda06504ef5",
    "ExecuteTime": {
     "end_time": "2023-12-09T16:25:42.470033388Z",
     "start_time": "2023-12-09T16:25:42.468451009Z"
    }
   },
   "outputs": [],
   "source": [
    "# specify train directory\n",
    "train_directory = os.path.join(ROOT_PATH, 'data', 'raw', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5dfbbf47dcd0846",
   "metadata": {
    "executionInfo": {
     "elapsed": 66794,
     "status": "ok",
     "timestamp": 1700508678052,
     "user": {
      "displayName": "Jan Kokla",
      "userId": "12594254134589162600"
     },
     "user_tz": -60
    },
    "id": "e5dfbbf47dcd0846",
    "ExecuteTime": {
     "end_time": "2023-12-09T16:25:42.972360640Z",
     "start_time": "2023-12-09T16:25:42.471126109Z"
    }
   },
   "outputs": [],
   "source": [
    "# image paths so that all the images are used for train dataset (no test set for cv due to small training set)\n",
    "image_path_train, _, mask_path_train, _ = split_data(train_directory, test_size=0)\n",
    "\n",
    "# create train Dataset without transformations for now\n",
    "train_dataset = RoadDataset(image_path_train, mask_path_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ca6d59a354e03a",
   "metadata": {
    "collapsed": false,
    "id": "86ca6d59a354e03a"
   },
   "source": [
    "## Hyperparameters\n",
    "\n",
    "Since our aim is to see, how different transformations influence the training, we fix the model, epochs and batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6bb08833d345ec0",
   "metadata": {
    "executionInfo": {
     "elapsed": 761,
     "status": "ok",
     "timestamp": 1700508695367,
     "user": {
      "displayName": "Jan Kokla",
      "userId": "12594254134589162600"
     },
     "user_tz": -60
    },
    "id": "a6bb08833d345ec0",
    "ExecuteTime": {
     "end_time": "2023-12-09T16:25:42.976753511Z",
     "start_time": "2023-12-09T16:25:42.975219606Z"
    }
   },
   "outputs": [],
   "source": [
    "ENCODER = 'resnet50'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "\n",
    "SEED = 16\n",
    "BATCH_SIZE = 4\n",
    "K_FOLD = 3\n",
    "N_CPU = os.cpu_count()\n",
    "N_EPOCHS = 100\n",
    "\n",
    "LOADER_PARAMS = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'num_workers': N_CPU,\n",
    "    'persistent_workers': True\n",
    "}\n",
    "\n",
    "# Albumentations use many separate image augmentation libraries with different sources for randomization. This is the best effort to have reproducible results. \n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformations\n",
    "\n",
    "Define transformations we'll use in evaluating the performance of the model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51e794b627f2d1ed"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Transforms that will always be applied\n",
    "base_tf = [A.Resize(height=608, width=608, always_apply=True)]\n",
    "\n",
    "# Optional transforms that we want to test\n",
    "transforms_dict = {\n",
    "    \"flip\": A.Flip(p=0.5),\n",
    "    \"rotate\": A.Rotate(p=0.5, limit=180, border_mode=cv2.BORDER_CONSTANT, rotate_method=\"ellipse\"),\n",
    "    \"brightness\": A.RandomBrightnessContrast(p=0.5),\n",
    "    \"shadow\": A.RandomShadow(p=0.5,num_shadows_lower=1, num_shadows_upper=4),\n",
    "    \"coarse dropout\": A.CoarseDropout(max_holes=8, max_height=50, max_width=50, min_holes=None, min_height=25, min_width=25,)\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:25:42.983225863Z",
     "start_time": "2023-12-09T16:25:42.977255290Z"
    }
   },
   "id": "b8db531ec43bc422"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(), ('flip',), ('rotate',), ('brightness',), ('shadow',), ('coarse dropout',), ('flip', 'rotate'), ('flip', 'brightness'), ('flip', 'shadow'), ('flip', 'coarse dropout'), ('rotate', 'brightness'), ('rotate', 'shadow'), ('rotate', 'coarse dropout'), ('brightness', 'shadow'), ('brightness', 'coarse dropout'), ('shadow', 'coarse dropout')]\n"
     ]
    }
   ],
   "source": [
    "# initiate the setups for transformations\n",
    "col_names = transforms_dict.keys()\n",
    "\n",
    "# Test optional transforms:\n",
    "# 1. No transform\n",
    "# 2. All transforms individually\n",
    "# 3. All possible pairs of transforms\n",
    "transform_combinations = [()] + list(itertools.combinations(col_names, 1)) + list(itertools.combinations(col_names, 2))\n",
    "print(transform_combinations)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:25:42.986564818Z",
     "start_time": "2023-12-09T16:25:42.983909381Z"
    }
   },
   "id": "87806847173ab4ed"
  },
  {
   "cell_type": "markdown",
   "id": "64a4294fcf3a7200",
   "metadata": {
    "collapsed": false,
    "id": "64a4294fcf3a7200"
   },
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This cross validation on 16 different combinations took around 7h to train on a RTX 3070 with following presets:\n",
    "```\n",
    "ENCODER = 'resnet50'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "K_FOLD = 3\n",
    "N_EPOCHS = 100\n",
    "model = \"DeepLabV3Plus\"\n",
    "```\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2216d7af77ef594"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 705616,
     "status": "ok",
     "timestamp": 1700509405450,
     "user": {
      "displayName": "Jan Kokla",
      "userId": "12594254134589162600"
     },
     "user_tz": -60
    },
    "id": "initial_id",
    "outputId": "0051ace9-0448-4556-f4af-58d3f1cf7df9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup: ()\n",
      "fold: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   1. Train.      Loss: 0.524 | f1: 0.526: 100%|██████████| 17/17 [00:06<00:00,  2.56it/s]\n",
      "Epoch:   1. Validation. Loss: 0.635 | f1: 0.337: 100%|██████████| 9/9 [00:01<00:00,  6.47it/s]\n",
      "Epoch:   2. Train.      Loss: 0.330 | f1: 0.721: 100%|██████████| 17/17 [00:04<00:00,  3.96it/s]\n",
      "Epoch:   2. Validation. Loss: 0.453 | f1: 0.634: 100%|██████████| 9/9 [00:00<00:00, 12.76it/s]\n",
      "Epoch:   3. Train.      Loss: 0.250 | f1: 0.790: 100%|██████████| 17/17 [00:04<00:00,  3.95it/s]\n",
      "Epoch:   3. Validation. Loss: 0.328 | f1: 0.707: 100%|██████████| 9/9 [00:00<00:00, 13.01it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 39\u001B[0m\n\u001B[1;32m     33\u001B[0m scheduler_ \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mlr_scheduler\u001B[38;5;241m.\u001B[39mCosineAnnealingLR(\n\u001B[1;32m     34\u001B[0m     optimizer_,\n\u001B[1;32m     35\u001B[0m     T_max\u001B[38;5;241m=\u001B[39m(\u001B[38;5;28mlen\u001B[39m(train_loader\u001B[38;5;241m.\u001B[39mdataset) \u001B[38;5;241m*\u001B[39m N_EPOCHS) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m train_loader\u001B[38;5;241m.\u001B[39mbatch_size,\n\u001B[1;32m     36\u001B[0m )\n\u001B[1;32m     38\u001B[0m \u001B[38;5;66;03m# Train model\u001B[39;00m\n\u001B[0;32m---> 39\u001B[0m train_losses, valid_losses, train_f1s, valid_f1s \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_loader\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mN_EPOCHS\u001B[49m\n\u001B[1;32m     41\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;66;03m# Save epoch results\u001B[39;00m\n\u001B[1;32m     44\u001B[0m training_f1_matrix\u001B[38;5;241m.\u001B[39mappend(np\u001B[38;5;241m.\u001B[39marray(train_f1s))\n",
      "File \u001B[0;32m~/repod/ml-project-2-odds-oddities/scripts/training.py:186\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(model, dataloaders, criterion, optimizer, scheduler, num_epochs)\u001B[0m\n\u001B[1;32m    182\u001B[0m train_losses, valid_losses, train_f1s, valid_f1s \u001B[38;5;241m=\u001B[39m [], [], [], []\n\u001B[1;32m    184\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[0;32m--> 186\u001B[0m     train_loss, train_f1 \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\n\u001B[1;32m    188\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    189\u001B[0m     valid_loss, val_f1 \u001B[38;5;241m=\u001B[39m valid_epoch(\n\u001B[1;32m    190\u001B[0m         model, valid_loader, criterion, i \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    191\u001B[0m     )\n\u001B[1;32m    193\u001B[0m     train_losses\u001B[38;5;241m.\u001B[39mappend(train_loss)\n",
      "File \u001B[0;32m~/repod/ml-project-2-odds-oddities/scripts/training.py:84\u001B[0m, in \u001B[0;36mtrain_epoch\u001B[0;34m(model, dataloader, criterion, optimizer, scheduler, epoch, **kwargs)\u001B[0m\n\u001B[1;32m     81\u001B[0m prediction_monitor\u001B[38;5;241m.\u001B[39mupdate(logits\u001B[38;5;241m.\u001B[39msigmoid(), labels, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtraining\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m prediction_monitor \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     83\u001B[0m tp, fp, fn, tn \u001B[38;5;241m=\u001B[39m smp\u001B[38;5;241m.\u001B[39mmetrics\u001B[38;5;241m.\u001B[39mget_stats(logits\u001B[38;5;241m.\u001B[39msigmoid(), labels, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m'\u001B[39m, threshold\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m)\n\u001B[0;32m---> 84\u001B[0m f1_score \u001B[38;5;241m=\u001B[39m \u001B[43msmp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmetrics\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf1_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmicro-imagewise\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     86\u001B[0m metric_monitor\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoss\u001B[39m\u001B[38;5;124m\"\u001B[39m, loss\u001B[38;5;241m.\u001B[39mitem())\n\u001B[1;32m     87\u001B[0m metric_monitor\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mf1\u001B[39m\u001B[38;5;124m\"\u001B[39m, f1_score\u001B[38;5;241m.\u001B[39mitem())\n",
      "File \u001B[0;32m~/repod/ml-project-2-odds-oddities/.venv/lib/python3.10/site-packages/segmentation_models_pytorch/metrics/functional.py:404\u001B[0m, in \u001B[0;36mf1_score\u001B[0;34m(tp, fp, fn, tn, reduction, class_weights, zero_division)\u001B[0m\n\u001B[1;32m    394\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mf1_score\u001B[39m(\n\u001B[1;32m    395\u001B[0m     tp: torch\u001B[38;5;241m.\u001B[39mLongTensor,\n\u001B[1;32m    396\u001B[0m     fp: torch\u001B[38;5;241m.\u001B[39mLongTensor,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    401\u001B[0m     zero_division: Union[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mfloat\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.0\u001B[39m,\n\u001B[1;32m    402\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[1;32m    403\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"F1 score\"\"\"\u001B[39;00m\n\u001B[0;32m--> 404\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_compute_metric\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    405\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_fbeta_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    406\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    407\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    408\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    409\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    410\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1.0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    411\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreduction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreduction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    412\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclass_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclass_weights\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    413\u001B[0m \u001B[43m        \u001B[49m\u001B[43mzero_division\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mzero_division\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    414\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/repod/ml-project-2-odds-oddities/.venv/lib/python3.10/site-packages/segmentation_models_pytorch/metrics/functional.py:253\u001B[0m, in \u001B[0;36m_compute_metric\u001B[0;34m(metric_fn, tp, fp, fn, tn, reduction, class_weights, zero_division, **metric_kwargs)\u001B[0m\n\u001B[1;32m    250\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClass weights should be provided for `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mreduction\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` reduction\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    252\u001B[0m class_weights \u001B[38;5;241m=\u001B[39m class_weights \u001B[38;5;28;01mif\u001B[39;00m class_weights \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m1.0\u001B[39m\n\u001B[0;32m--> 253\u001B[0m class_weights \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclass_weights\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    254\u001B[0m class_weights \u001B[38;5;241m=\u001B[39m class_weights \u001B[38;5;241m/\u001B[39m class_weights\u001B[38;5;241m.\u001B[39msum()\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m reduction \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmicro\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "metric_dict = {}\n",
    "\n",
    "for setup in transform_combinations:\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    print(f'setup: {str(setup)}')\n",
    "\n",
    "    # get the picked tfs as list\n",
    "    tf_selection = base_tf + [transforms_dict[t] for t in setup]\n",
    "\n",
    "    k_fold = KFold(n_splits=K_FOLD, shuffle=True, random_state=SEED)\n",
    "\n",
    "    # Record K-fold results in a (K_FOLD, num_epoch) matrix\n",
    "    training_f1_matrix = []\n",
    "    validation_f1_matrix = []\n",
    "\n",
    "    train_tf = A.Compose(base_tf + tf_selection)\n",
    "    valid_tf = A.Compose(base_tf)\n",
    "\n",
    "    # Get training and validation indices\n",
    "    for fold, (train_idx, val_idx) in enumerate(k_fold.split(train_dataset)):\n",
    "        \n",
    "        print(f'fold: {fold}')\n",
    "\n",
    "        # Create training and validation loaders by providing current K-Fold train/validation indices to Sampler\n",
    "        train_loader = DataLoader(train_dataset.set_tf(train_tf), sampler=SubsetRandomSampler(train_idx), **LOADER_PARAMS)\n",
    "        valid_loader = DataLoader(train_dataset.set_tf(valid_tf), sampler=SubsetRandomSampler(val_idx), **LOADER_PARAMS)\n",
    "\n",
    "        # Initialize model\n",
    "        model_ = smp.create_model(\"DeepLabV3Plus\", encoder_name=ENCODER, encoder_weights=ENCODER_WEIGHTS)\n",
    "        criterion_ = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
    "        optimizer_ = torch.optim.Adam(model_.parameters(), lr=0.0005)\n",
    "        scheduler_ = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer_,\n",
    "            T_max=(len(train_loader.dataset) * N_EPOCHS) // train_loader.batch_size,\n",
    "        )\n",
    "\n",
    "        # Train model\n",
    "        train_losses, valid_losses, train_f1s, valid_f1s = train_model(\n",
    "            model_, (train_loader, valid_loader), criterion_, optimizer_, scheduler_, N_EPOCHS\n",
    "        )\n",
    "\n",
    "        # Save epoch results\n",
    "        training_f1_matrix.append(np.array(train_f1s))\n",
    "        validation_f1_matrix.append(np.array(valid_f1s))\n",
    "    \n",
    "    metric_dict[\", \".join(setup)] = validation_f1_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd70cdcdc704f9da",
   "metadata": {
    "collapsed": false,
    "id": "fd70cdcdc704f9da"
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use the mean F1 score of each epoch as the representative value."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "855a119e7bd4cb71"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfec4d7529b8b3c",
   "metadata": {
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1700509432539,
     "user": {
      "displayName": "Jan Kokla",
      "userId": "12594254134589162600"
     },
     "user_tz": -60
    },
    "id": "cdfec4d7529b8b3c",
    "ExecuteTime": {
     "start_time": "2023-12-09T16:26:03.133025742Z"
    }
   },
   "outputs": [],
   "source": [
    "f1s = []\n",
    "last_f1s = []\n",
    "std_devs = []\n",
    "last_std_devs = []\n",
    "\n",
    "for matrix in metric_dict.values():\n",
    "    # Each matrix corresponds to all the k-fold results of one transform \n",
    "    matrix = np.array(matrix)\n",
    "    \n",
    "    # Find the mean F1 of each epoch\n",
    "    mean_per_epoch = matrix.mean(axis=0)\n",
    "    \n",
    "    # Save the F1 and std of the best epoch\n",
    "    best_epoch = mean_per_epoch.argmax()\n",
    "    f1s.append(mean_per_epoch.max())\n",
    "    std_devs.append(matrix[:, best_epoch].std())\n",
    "    \n",
    "    # Save the F1 and std of the last epoch\n",
    "    last_f1s.append(matrix[:,-1].mean())\n",
    "    last_std_devs.append(matrix[:,-1].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eae8e5b749d4c6",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1700509433650,
     "user": {
      "displayName": "Jan Kokla",
      "userId": "12594254134589162600"
     },
     "user_tz": -60
    },
    "id": "e8eae8e5b749d4c6",
    "ExecuteTime": {
     "start_time": "2023-12-09T16:26:03.142958004Z"
    }
   },
   "outputs": [],
   "source": [
    "# Construct a pandas df \n",
    "final_df = pd.DataFrame(index=metric_dict.keys(), columns=['top-f1', 'top-std', 'last-f1', 'last-std'], data=np.array([f1s, std_devs, last_f1s, last_std_devs]).T)\n",
    "# Use timestamp in file name to avoid accidentally overwriting important results\n",
    "final_df.to_csv(os.path.join(ROOT_PATH, 'data', 'results', 'transforms', f'transform_results_{int(time.time())}.csv'))\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generate the Latex table for our research paper\n",
    "print(final_df.to_latex(columns=[\"top-f1\", 'top-std'], header=[\"top-f1\",\"std\"], float_format=\"%.3f\", caption=\"The best results k-fold (mean) result\", label=\"table:transform-results\", position=\"h!\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-09T16:26:03.143035467Z"
    }
   },
   "id": "7b615b15cd62aa0d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualize Transformations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7f0ea6599694fc3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HQkAhvruq7ls",
   "metadata": {
    "id": "HQkAhvruq7ls",
    "ExecuteTime": {
     "start_time": "2023-12-09T16:26:03.143051564Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#transform = A.Compose(pd.Series(added_tfs).explode().tolist())\n",
    "\n",
    "# 1 base image + 1 image per transform\n",
    "image_count = 1 + len(transforms_dict)\n",
    "\n",
    "# Collage column count can be chosen and row count will then be computed based on the number of images  \n",
    "COLLAGE_COLUMNS = 3\n",
    "COLLAGE_ROWS = math.ceil(image_count / COLLAGE_COLUMNS)\n",
    "\n",
    "# Get sample image and change axis ordering back from Pytorch format\n",
    "original_img = train_dataset[0][0]\n",
    "original_img = np.moveaxis(original_img, 0, -1)\n",
    "\n",
    "# Plot unaltered image\n",
    "fig = plt.figure(layout='tight')\n",
    "ax1 = fig.add_subplot(COLLAGE_ROWS, COLLAGE_COLUMNS, 1)\n",
    "ax1.imshow(original_img, cmap=\"Greys_r\")\n",
    "ax1.set_title(\"original\")\n",
    "ax1.axis(\"off\")\n",
    "\n",
    "# Add image to the grid for each separate transform\n",
    "for idx, (label, t) in enumerate(transforms_dict.items()):\n",
    "    \n",
    "    # Transformations are generally only applied with some probability e.g 0.5. Here we want to definitely apply it.\n",
    "    t.always_apply=True \n",
    "    transformed_img = t(image=original_img)[\"image\"]\n",
    "    \n",
    "    # Plot transformed image\n",
    "    ax2 = fig.add_subplot(COLLAGE_ROWS, COLLAGE_COLUMNS, idx + 2)\n",
    "    ax2.imshow(transformed_img)\n",
    "    ax2.set_title(label)\n",
    "    ax2.axis(\"off\")\n",
    "    ax2.margins(x=0.1, y=5)\n",
    "    \n",
    "fig.savefig(ROOT_PATH + \"/data/results/transforms/transform_collage.png\", dpi=100)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
