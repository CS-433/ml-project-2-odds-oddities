{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44e77324caeb7103",
   "metadata": {
    "collapsed": false,
    "id": "44e77324caeb7103"
   },
   "source": [
    "# Final Training\n",
    "\n",
    "This is continuation to hyperparameter optimization. Since we have found best mix of hyperparameters for every model used in ensembling, we can now use the whole training set for the final training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3bd0b296096edc",
   "metadata": {
    "collapsed": false,
    "id": "5c3bd0b296096edc"
   },
   "source": [
    "## Google Colab\n",
    "\n",
    "The following two cells will only be necessary in Google Colab. To avoid problems with imports, they are included in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    # noinspection PyUnresolvedReferences\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount('/content/drive')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T08:06:41.134612Z",
     "start_time": "2023-12-14T08:06:41.005102Z"
    }
   },
   "id": "6b9c7561c0988e12"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# let's keep this cell at the beginning for every notebook\n",
    "# for more convenient training in Google Colab\n",
    "def get_root_path(filename: str) -> str:\n",
    "    \"\"\"Get root path based on notebook's name.\"\"\"\n",
    "    filepath = glob.glob(os.getcwd() + '/**/' + filename, recursive=True)[0]\n",
    "    return os.path.dirname(os.path.dirname(filepath))\n",
    "\n",
    "ROOT_PATH = get_root_path('final_training.ipynb')\n",
    "sys.path.append(ROOT_PATH)\n",
    "\n",
    "# go to the drive directory\n",
    "os.chdir(ROOT_PATH) if IN_COLAB else None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T08:06:41.135411Z",
     "start_time": "2023-12-14T08:06:41.012126Z"
    }
   },
   "id": "6ca28bc5245f155c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d624e0026c589fad"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "import albumentations as A\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from scripts.preprocessing import RoadDataset, split_data, get_preprocessing\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "from scripts.training import setup_seed, train_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T08:06:48.561904Z",
     "start_time": "2023-12-14T08:06:41.019848Z"
    }
   },
   "id": "661a28fbc323f84c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# hacky way for avoid problems with SSL when downloading some of the models\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T08:06:48.569938Z",
     "start_time": "2023-12-14T08:06:48.562694Z"
    }
   },
   "id": "fa5d6575c4861306"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "SEED = 16\n",
    "setup_seed(16)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T08:06:48.578164Z",
     "start_time": "2023-12-14T08:06:48.568023Z"
    }
   },
   "id": "4db7d71f1c441221"
  },
  {
   "cell_type": "markdown",
   "id": "cc8cd208897a9308",
   "metadata": {
    "collapsed": false,
    "id": "cc8cd208897a9308"
   },
   "source": [
    "## Data\n",
    "\n",
    "Specify the data directory and transformations. Notice that the data must first be downloaded using bash script (see README)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c4f4dda06504ef5",
   "metadata": {
    "executionInfo": {
     "elapsed": 443,
     "status": "ok",
     "timestamp": 1700508609231,
     "user": {
      "displayName": "Jan Kokla",
      "userId": "12594254134589162600"
     },
     "user_tz": -60
    },
    "id": "1c4f4dda06504ef5",
    "ExecuteTime": {
     "end_time": "2023-12-14T08:06:48.578534Z",
     "start_time": "2023-12-14T08:06:48.575099Z"
    }
   },
   "outputs": [],
   "source": [
    "# specify train directory\n",
    "train_directory = os.path.join(ROOT_PATH, 'data', 'raw', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# define transformations\n",
    "train_tf = A.Compose([\n",
    "    A.Resize(height=608, width=608, always_apply=True),\n",
    "    A.Rotate(p=0.5, limit=180, border_mode=cv2.BORDER_CONSTANT, rotate_method=\"ellipse\"),\n",
    "    A.RandomBrightnessContrast(p=0.5)\n",
    "])\n",
    "\n",
    "valid_tf = A.Compose([A.Resize(height=608, width=608, always_apply=True)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T08:06:48.608250Z",
     "start_time": "2023-12-14T08:06:48.580734Z"
    }
   },
   "id": "b8db531ec43bc422"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "preprocess_input = get_preprocessing_fn('inceptionv4', pretrained='imagenet')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T08:06:48.608665Z",
     "start_time": "2023-12-14T08:06:48.586164Z"
    }
   },
   "id": "c313514538e029f"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# keep only training data (validation proportion=0)\n",
    "image_path_train, _, mask_path_train, _ = split_data(train_directory, 0)\n",
    "train_dataset = RoadDataset(image_path_train, mask_path_train, train_tf, get_preprocessing(preprocess_input))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T08:06:50.104796Z",
     "start_time": "2023-12-14T08:06:48.591320Z"
    }
   },
   "id": "fcca102343c889cc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters\n",
    "\n",
    "As"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22430d9a319db8e4"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "ENCODER = 'inceptionv4'\n",
    "DECODER = 'UnetPlusPlus'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T08:06:50.115486Z",
     "start_time": "2023-12-14T08:06:50.107050Z"
    }
   },
   "id": "42517c0efc0c67fa"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "config_path = os.path.join(ROOT_PATH, 'data', 'results', 'hyperopt', 'configs.json')\n",
    "with open(config_path, 'r') as file:\n",
    "  data = json.load(file)\n",
    "  \n",
    "model = \"+\".join([ENCODER, DECODER])\n",
    "config = data[model]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T08:06:50.116869Z",
     "start_time": "2023-12-14T08:06:50.112257Z"
    }
   },
   "id": "aa8e5029c07b0516"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6c64f50d3c97d4e"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Create training and validation loaders by providing current K-Fold train/validation indices to Sampler\n",
    "loader = DataLoader(train_dataset.set_tf(train_tf), config['batch_size'])\n",
    "\n",
    "# Initialize model\n",
    "model = smp.create_model(DECODER, encoder_name=ENCODER, classes=1)\n",
    "model.encoder.training=False\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), config['lr'])\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=(len(loader.dataset) * int(config['num_epochs'])) // loader.batch_size,\n",
    ")\n",
    "\n",
    "criteria_dict = {\n",
    "        'dice_loss': smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True),\n",
    "        'focal_loss': smp.losses.FocalLoss(smp.losses.BINARY_MODE)\n",
    "    }\n",
    "criterion = criteria_dict[config[\"criterion\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T08:40:17.602597Z",
     "start_time": "2023-12-14T08:40:15.798024Z"
    }
   },
   "id": "44f182fc1a824760"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transforming!\n",
      "transforming!\n",
      "transforming!\n",
      "transforming!\n",
      "transforming!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   1. Train.      Loss: 0.275 | f1: 0.260:   5%|▌         | 1/20 [01:05<20:51, 65.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transforming!\n",
      "transforming!\n",
      "transforming!\n",
      "transforming!\n",
      "transforming!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   1. Train.      Loss: 0.275 | f1: 0.260:   5%|▌         | 1/20 [02:05<39:39, 125.23s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m _ \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mnum_epochs\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/EPFL/ml-project-2-odds-oddities/scripts/training.py:150\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(model, dataloaders, criterion, optimizer, scheduler, num_epochs, **kwargs)\u001B[0m\n\u001B[1;32m    146\u001B[0m train_losses, valid_losses, train_f1s, valid_f1s \u001B[38;5;241m=\u001B[39m [], [], [], []\n\u001B[1;32m    148\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[0;32m--> 150\u001B[0m     train_loss, train_f1 \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\n\u001B[1;32m    152\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    153\u001B[0m     train_losses\u001B[38;5;241m.\u001B[39mappend(train_loss)\n\u001B[1;32m    154\u001B[0m     train_f1s\u001B[38;5;241m.\u001B[39mappend(train_f1)\n",
      "File \u001B[0;32m~/Documents/EPFL/ml-project-2-odds-oddities/scripts/training.py:48\u001B[0m, in \u001B[0;36mtrain_epoch\u001B[0;34m(model, dataloader, criterion, optimizer, scheduler, epoch, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m logits \u001B[38;5;241m=\u001B[39m model(inputs\u001B[38;5;241m.\u001B[39mfloat())\n\u001B[1;32m     47\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(logits, labels\u001B[38;5;241m.\u001B[39mfloat())\n\u001B[0;32m---> 48\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     50\u001B[0m scheduler\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/Documents/EPFL/ml-project-2-odds-oddities/.venv/lib/python3.9/site-packages/torch/_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    491\u001B[0m     )\n\u001B[0;32m--> 492\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/EPFL/ml-project-2-odds-oddities/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 251\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "_ = train_model(\n",
    "    model, (loader, None), criterion, optimizer, scheduler, int(config['num_epochs'])\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T08:42:24.375909Z",
     "start_time": "2023-12-14T08:40:18.822307Z"
    }
   },
   "id": "82be04516937c9ca"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save State Dict"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9e76d3284d9ba77"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "state_dict_path = os.path.join(ROOT_PATH, 'data', 'results', 'final_models', f'{ENCODER}+{DECODER}.pth')\n",
    "model_name = \"+\".join([ENCODER, DECODER])\n",
    "\n",
    "torch.save({'state_dict': model.state_dict()}, state_dict_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T08:07:34.793996Z",
     "start_time": "2023-12-14T08:07:34.790507Z"
    }
   },
   "id": "bfda552773366b25"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T08:07:34.796275Z",
     "start_time": "2023-12-14T08:07:34.795388Z"
    }
   },
   "id": "eda4518173c982e"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
